import streamlit as st
import pandas as pd
import utils
import json
import time # æ–°å¢ï¼šç”¨äºé¢‘ç‡æ§åˆ¶
from scrapers.internal_generator import MACRO_OPEN_QUESTIONS

st.set_page_config(page_title="å®è§‚ç›‘æ§", page_icon="ğŸŒ", layout="wide")
utils.inject_custom_css()
st.title("ğŸŒ å®è§‚ç›‘æ§ (Macro)")
# --- [æ¶æ„å¸ˆæ–°å¢] ä¾§è¾¹æ ï¼šAI ç”ŸæˆåŠŸèƒ½ ---
with st.sidebar:
    st.markdown("### ğŸ› ï¸ æƒ…æŠ¥å·¥å…·ç®±")
    if st.button("ğŸš€ AIç”Ÿæˆå®è§‚", type="primary", use_container_width=True):
        with st.status("æ­£åœ¨è°ƒåŠ¨ AI è¿›è¡Œæ·±åº¦èŒƒå¼æ¨æ¼”...", expanded=True) as status:
            for i, q in enumerate(MACRO_OPEN_QUESTIONS):
                st.write(f"æ­£åœ¨ç ”åˆ¤ç¬¬ {i+1}/{len(MACRO_OPEN_QUESTIONS)} ç»„ç»´åº¦...")
                
                # æ„é€ å¼•å¯¼ Promptï¼Œç¡®ä¿ AI ä¿æŒé«˜æ°´å‡†è¾“å‡º 
                structured_prompt = f"ã€ç³»ç»ŸæŒ‡ä»¤ï¼šæ‰§è¡Œå®è§‚èŒƒå¼ä¸“é¡¹ç ”åˆ¤ã€‘\n\nç ”åˆ¤ç»´åº¦ï¼š{q}"
                
                # è°ƒç”¨ utils æ ¸å¿ƒåˆ†å‘å‡½æ•° 
                # è¿™ä¼šè‡ªåŠ¨å®Œæˆï¼šAIåˆ†æ -> GitHubå­˜å…¥00(åŸæ–‡)å’Œ01(å¡ç‰‡) -> Google Sheets è®°å½•
                utils.auto_dispatch(None, structured_prompt)
                
                time.sleep(1.5) # é¢‘ç‡ä¿æŠ¤ï¼Œé˜²æ­¢ API è§¦å‘é€Ÿç‡é™åˆ¶
            
            status.update(label="âœ… å®è§‚ç ”åˆ¤ç”Ÿæˆå®Œæ¯•ï¼", state="complete", expanded=False)
        
        st.toast("æƒ…æŠ¥å·²åŒæ­¥è‡³ Google Sheets åŠ GitHub", icon="ğŸ’¾")
        time.sleep(1)
        st.rerun() # è‡ªåŠ¨åˆ·æ–°é¡µé¢ï¼Œå±•ç¤ºæœ€æ–°ç”Ÿæˆçš„æƒ…æŠ¥
# --- åŠ è½½æ•°æ® ---
try:
    raw_data = utils.load_data(sheet_name="macro_stream")
    st.session_state['macro_data'] = raw_data
except:
    st.session_state['macro_data'] = []

df = pd.DataFrame(st.session_state['macro_data'])
if 'case_files' not in st.session_state: st.session_state['case_files'] = []

# --- æ°´ä½ä»ª ---
with st.expander("ğŸ¦… å®è§‚æ°´ä½ä»ª", expanded=True):
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("æµåŠ¨æ€§", "Neutral")
    c2.metric("ç¾è”å‚¨", "Hawkish")
    c3.metric("10Y ç¾å€º", "4.15%")
    c4.metric("é€šèƒ€é¢„æœŸ", "2.3%")

st.divider()

# --- æƒ…æŠ¥æµ ---
if len(st.session_state['case_files']) > 0:
    st.toast(f"ğŸ•µï¸ æ¡ˆå·åº“ç°æœ‰ {len(st.session_state['case_files'])} ä»½æƒ…æŠ¥", icon="ğŸ“‚")

st.subheader(f"ğŸ“‹ å®è§‚æƒ…æŠ¥æµ ({len(df)})")

h1, h2, h3, h4, h5 = st.columns([1.5, 1, 6, 2, 1])
h1.markdown("**æ—¶é—´**")
h2.markdown("**åå‘**")
h3.markdown("**ç»“è®º & é€»è¾‘**")
h4.markdown("**æ ‡ç­¾ & æ¥æº**")
h5.markdown("**å¹¶æ¡ˆ**")
st.markdown("---")

for i, item in enumerate(st.session_state['macro_data']):
    with st.container():
        c1, c2, c3, c4, c5 = st.columns([1.5, 1, 6, 2, 1])
        
        # 1. æ—¶é—´
        c1.caption(item.get('date', 'N/A'))
        pub_date = item.get('publication_date', 'Unknown')
        if pub_date and pub_date != 'Unknown':
            c1.caption(f"åŸæ–‡: {pub_date}")
        
        # 2. åå‘
        bias = item.get('bias', 'Neutral')
        if bias == 'Bullish': c2.markdown(":green[**Bullish**]")
        elif bias == 'Bearish': c2.markdown(":red[**Bearish**]")
        else: c2.markdown(":gray[Neutral]")
        
        # 3. æ ¸å¿ƒå±•ç¤º
        title = item.get('title', '').strip()
        summary = item.get('summary', '').strip()
        logic = item.get('logic_chain_display', '').strip()
        
        # æ ‡é¢˜å…œåº•ç­–ç•¥
        display_title = title
        if not display_title or display_title in ["æ— ç»“è®º", "æ— æ ‡é¢˜"]:
            if summary: display_title = summary
            elif logic: display_title = logic
            else: display_title = "æš‚æ— ç»“è®º"
        
        # é“¾æ¥
        # ğŸ‘‡ åŠ ä¸Š .replace(' ', '%20') ä¿®å¤ç©ºæ ¼å¯¼è‡´é“¾æ¥æ–­è£‚çš„é—®é¢˜
        raw_link = item.get('raw_doc_link', '#').replace(' ', '%20')
        card_link = item.get('card_link', '#').replace(' ', '%20') 
        
        # A. ç»“è®º
        if raw_link == "#error_no_token":
             c3.markdown(f"#### {display_title} (âš ï¸GitHubé…ç½®é”™è¯¯)")
        else:
             c3.markdown(f"#### [{display_title}]({raw_link})")
            
        # B. é€»è¾‘é“¾ (ä¿®å¤ï¼šæ¸…æ´—æ‹¬å·)
        if logic and logic != "æ— ":
            # ğŸ‘‡ å…³é”®ä¿®å¤ï¼šæŠŠ AI ç”Ÿæˆçš„ä¸­æ‹¬å·åˆ æ‰ï¼Œé˜²æ­¢ Markdown é“¾æ¥å¤±æ•ˆ
            clean_logic = logic.replace('[', '').replace(']', '')
            
            if card_link == "#error_no_token":
                c3.info(f"â›“ï¸ **é€»è¾‘**: {clean_logic}")
            else:
                c3.info(f"â›“ï¸ **é€»è¾‘**: [{clean_logic}]({card_link})")
        
        # 4. æ ‡ç­¾ & æ¥æº
        tags = item.get('tags', [])
        if isinstance(tags, str):
            try: tags = json.loads(tags.replace("'", '"'))
            except: tags = [str(tags)]
        if tags and isinstance(tags, list):
            c4.markdown(" ".join([f"`{t}`" for t in tags[:3]]))
        
        url = item.get('url', '').strip()
        if url:
            if url.startswith("http"): c4.markdown(f"[ğŸ”— åŸæ–‡]({url})")
            elif url == "Telegram Bot": c4.caption("ğŸ¤– Telegram")
            elif url == "Manual": c4.caption("ğŸ“ æ‰‹åŠ¨å½•å…¥")
            else: c4.caption(f"æ¥æº: {url}")
        else:
            c4.caption("æ¥æº: æœªçŸ¥")

        # 5. æ“ä½œ
        current_sum = item.get('summary', '') 
        is_in_cart = any(case.get('summary') == current_sum for case in st.session_state['case_files'])
        if is_in_cart:
            c5.button("âœ…", key=f"mac_done_{i}", disabled=True)
        else:
            if c5.button("â•", key=f"mac_add_{i}"):
                st.session_state['case_files'].append(item)
                st.rerun()
            
        st.markdown("<div style='margin-bottom: 12px; border-bottom: 1px solid #333;'></div>", unsafe_allow_html=True)