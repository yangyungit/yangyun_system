import streamlit as st
import utils
import pandas as pd
import google.generativeai as genai

st.set_page_config(page_title="æƒ…æŠ¥ä¾¦æŸ¥å®¤", page_icon="ğŸ•µï¸", layout="wide")

st.title("ğŸ•µï¸ æ·±åº¦æƒ…æŠ¥ä¾¦æŸ¥å®¤ (Detective Room)")

# --- 1. è¯»å–æ¡ˆå· ---
if 'case_files' not in st.session_state or not st.session_state['case_files']:
    st.info("ğŸ“­ æ¡ˆå·åº“æ˜¯ç©ºçš„ã€‚è¯·å…ˆå» [å®è§‚] æˆ– [é›·è¾¾] é¡µé¢ç‚¹å‡» â• å·æ·»åŠ æƒ…æŠ¥ã€‚")
    st.stop()

files = st.session_state['case_files']

# --- 2. ä¾§è¾¹æ ï¼šæ¡ˆå·ç®¡ç† ---
with st.sidebar:
    st.header(f"ğŸ“‚ å¾…ä¾¦æŸ¥æ¡ˆå· ({len(files)})")
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ¡ˆå·", use_container_width=True):
        st.session_state['case_files'] = []
        st.rerun()
    st.divider()
    for idx, case in enumerate(files):
        st.markdown(f"**{idx+1}. {case.get('title', 'æ— æ ‡é¢˜')}**")
        cat = case.get('category', 'UNKNOWN')
        if cat == 'MACRO': st.caption("ğŸŒ å®è§‚æƒ…æŠ¥")
        else: st.caption("ğŸ“¡ é›·è¾¾æƒ…æŠ¥")
        if st.button("âŒ ç§»é™¤", key=f"del_case_{idx}"):
            files.pop(idx)
            st.session_state['case_files'] = files
            st.rerun()
        st.markdown("---")

# --- 3. æ¡ˆå·å†…å®¹é¢„è§ˆ (å››ç»´è§†å›¾) ---
with st.expander("æŸ¥çœ‹æ‰€æœ‰æ¡ˆå·çš„ã€å››ç»´ç»“æ„åŒ–çŸ¥è¯†ã€‘ (äº‹å®/è§‚ç‚¹/é€»è¾‘/å‡è®¾)", expanded=False):
    for i, f in enumerate(files):
        st.markdown(f"### ğŸ“„ æ¡ˆå· {i+1}: {f.get('title')}")
        # è¿™é‡Œå±•ç¤ºçš„æ˜¯ 01/02 é‡Œçš„æ·±åº¦åˆ†æå†…å®¹
        # å¦‚æœæ˜¯æ–°ç‰ˆ utils ç”Ÿæˆçš„ï¼Œè¿™é‡Œå·²ç»åŒ…å«äº†å››ä¸ªæ ‡é¢˜
        content = f.get('deep_analysis_md', 'âš ï¸ ç¼ºå°‘ç»“æ„åŒ–æ•°æ®')
        st.markdown(content)
        st.divider()

# --- 4. AI ä¾¦æ¢å·¥ä½œå° ---
st.subheader("ğŸ§  AI è”åˆä¾¦æŸ¥ (Joint Investigation)")

# æ„é€  Prompt ä¸Šä¸‹æ–‡
context_text = ""
for i, f in enumerate(files):
    content_payload = f.get('deep_analysis_md')
    if not content_payload:
        # å…¼å®¹æ—§æ•°æ®
        content_payload = f"æ‘˜è¦: {f.get('summary')} (ç¼ºå¤±ç»“æ„åŒ–åˆ†æ)"

    context_text += f"""
    === ğŸ•µï¸ æ¡ˆå· {i+1} ===
    ã€æ ‡é¢˜ã€‘: {f.get('title')}
    ã€åˆ†ç±»ã€‘: {f.get('category')}
    ã€ç»“æ„åŒ–çŸ¥è¯†å—ã€‘:
    {content_payload}
    ====================
    """

# é¢„è®¾é«˜é˜¶ä¾¦æŸ¥æŒ‡ä»¤ (é’ˆå¯¹å››ç»´åˆ‡åˆ†)
q_options = [
    "ğŸ” äº‹å® vs è§‚ç‚¹ï¼šè¯·å¸®æˆ‘æŠŠã€äº‹å®ã€‘å‰¥ç¦»å‡ºæ¥ï¼Œé‡æ–°è¯„ä¼°ä½œè€…çš„ã€è§‚ç‚¹ã€‘æ˜¯å¦è¿‡äºæ¿€è¿›ï¼Ÿ",
    "ğŸ”— é€»è¾‘é“¾å‹åŠ›æµ‹è¯•ï¼šæ£€æŸ¥ã€é€»è¾‘ã€‘æ¨å¯¼è¿‡ç¨‹ï¼Œå“ªé‡Œå­˜åœ¨æ–­è£‚æˆ–å¼ºè¡Œå½’å› ï¼Ÿ",
    "âš ï¸ å‡è®¾å´©å¡Œæ¨æ¼”ï¼šæ”»å‡»æ–‡ä¸­çš„ã€å‡è®¾ã€‘ï¼Œå¦‚æœè¿™äº›å‰æä¸æˆç«‹ï¼ˆä¾‹å¦‚é€šèƒ€åå¼¹äº†ï¼‰ï¼Œç»“è®ºä¼šå‘ç”Ÿä»€ä¹ˆé€†è½¬ï¼Ÿ",
    "âš”ï¸ è·¨æ¡ˆå·çŸ›ç›¾ï¼šæ¡ˆå·ä¹‹é—´æ˜¯å¦å­˜åœ¨ã€äº‹å®ã€‘å†²çªæˆ–ã€é€»è¾‘ã€‘äº’æ–¥ï¼Ÿ",
    "ğŸ’° åˆ¶å®šä½œæˆ˜è®¡åˆ’ï¼šåŸºäºä»¥ä¸Šäº‹å®å’Œé€»è¾‘ï¼Œæ„å»ºä¸€ä¸ªé«˜èƒœç‡äº¤æ˜“ç­–ç•¥ã€‚"
]

col_q1, col_q2 = st.columns([1, 1])
user_q = col_q1.selectbox("é€‰æ‹©ä¾¦æŸ¥æ–¹å‘:", q_options)
manual_q = col_q2.text_input("æˆ– ğŸ’¬ å‘ä¾¦æ¢æé—®:", placeholder="ä¾‹å¦‚ï¼šå¦‚æœå‡è®¾ä¸­çš„è‰¯å“ç‡ä¸åŠé¢„æœŸï¼Œè‚¡ä»·ä¸‹è·Œç©ºé—´æœ‰å¤šå°‘ï¼Ÿ")

final_q = manual_q if manual_q else user_q

if st.button("ğŸš€ å¼€å§‹å¹¶æ¡ˆä¾¦æŸ¥", type="primary"):
    with st.status("ğŸ•µï¸ ä¾¦æ¢æ­£åœ¨è¿›è¡Œå››ç»´å®¡è§†...", expanded=True) as status:
        try:
            # 1. é…ç½® AI
            api_key = utils.get_config("GOOGLE_API_KEY")
            if not api_key:
                st.error("âŒ ç¼ºå°‘ API Key")
                st.stop()
            
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-2.0-flash') 
            
            # 2. æ„é€  Prompt
            full_prompt = f"""
            ä½ æ˜¯ä¸€ä½æåº¦ç†æ€§çš„æƒ…æŠ¥ä¾¦æ¢ã€‚ä½ é¢å‰çš„æ¡ˆå·å·²ç»ç»è¿‡äº†ã€äº‹å®ã€è§‚ç‚¹ã€é€»è¾‘ã€å‡è®¾ã€‘çš„å››ç»´åˆ‡åˆ†ã€‚
            
            è¯·åŸºäºä»¥ä¸‹ã€æ¡ˆå·å†…å®¹ã€‘ï¼Œå›ç­”ã€æˆ‘çš„é—®é¢˜ã€‘ã€‚
            
            ã€æ¡ˆå·å†…å®¹ã€‘ï¼š
            {context_text}
            
            ã€æˆ‘çš„é—®é¢˜ã€‘ï¼š
            {final_q}
            
            ã€å›ç­”è¦æ±‚ã€‘ï¼š
            1. **äº‹å®æ ¸æŸ¥**ï¼šåœ¨å›ç­”æ—¶ï¼Œè¯·æ˜ç¡®å¼•ç”¨æ¡ˆå·ä¸­çš„ã€äº‹å®ã€‘éƒ¨åˆ†ä½œä¸ºè¯æ®ã€‚
            2. **è§‚ç‚¹éš”ç¦»**ï¼šä¸è¦è¢«åŸæ–‡çš„ã€è§‚ç‚¹ã€‘å¸¦åï¼Œè¦ç”¨æ‰¹åˆ¤æ€§çœ¼å…‰å®¡è§†å®ƒä»¬ã€‚
            3. **æ”»å‡»å‡è®¾**ï¼šé‡ç‚¹å…³æ³¨ã€å‡è®¾ã€‘éƒ¨åˆ†ï¼Œè¿™æ˜¯æœ€å®¹æ˜“å‡ºé”™çš„åœ°æ–¹ï¼Œè¯·è¿›è¡Œè¯ä¼ªã€‚
            4. è¾“å‡ºæ ¼å¼æ¸…æ™°ï¼Œä½¿ç”¨ Markdownã€‚
            """
            
            status.write("ğŸ§  æ­£åœ¨è¿›è¡Œé€»è¾‘å¯¹æŠ—ä¸å‡è®¾éªŒè¯...")
            response = model.generate_content(full_prompt)
            
            status.update(label="âœ… ä¾¦æŸ¥æŠ¥å‘Šå·²ç”Ÿæˆ", state="complete", expanded=False)
            
            st.markdown("### ğŸ“ ä¾¦æŸ¥æŠ¥å‘Š")
            st.markdown(response.text)
            
        except Exception as e:
            st.error(f"ä¾¦æŸ¥å¤±è´¥: {e}")