import streamlit as st
import gspread
import pandas as pd
import json
import os
import base64
import toml
import google.generativeai as genai
from datetime import datetime
import urllib.parse
from github import Github

# --- 1. åŸºç¡€é…ç½® ---
def ensure_secrets_file():
    secret_path = ".streamlit/secrets.toml"
    encoded = os.environ.get("STREAMLIT_SECRETS_B64")
    if encoded and not os.path.exists(secret_path):
        try:
            decoded = base64.b64decode(encoded.strip()).decode()
            os.makedirs(".streamlit", exist_ok=True)
            with open(secret_path, "w") as f: f.write(decoded)
        except: pass

ensure_secrets_file()

def get_config(key_name):
    # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡å– (Fly.io secrets)ï¼Œå…¶æ¬¡ä»æœ¬åœ°æ–‡ä»¶å–
    val = os.environ.get(key_name)
    if val: return val
    if os.path.exists(".streamlit/secrets.toml"):
        try:
            with open(".streamlit/secrets.toml", "r") as f:
                return toml.load(f).get(key_name)
        except: pass
    return None

def inject_custom_css():
    st.markdown("""
    <style>
        div[data-testid="stMarkdownContainer"] a {
            color: inherit !important;
            text-decoration: none !important;
            border-bottom: 1px dashed #666;
            transition: all 0.2s;
        }
        div[data-testid="stMarkdownContainer"] a:hover {
            color: #ffffff !important;
            text-decoration: underline !important;
            border-bottom: none;
        }
    </style>
    """, unsafe_allow_html=True)

# --- 2. Google Sheets ---
def get_gsheet_client():
    secret_file = ".streamlit/secrets.toml"
    try:
        scopes = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
        with open(secret_file, "r") as f:
            data = toml.load(f)
        creds = data.get("gcp_service_account") or data
        return gspread.service_account_from_dict(creds, scopes=scopes)
    except: return None

def load_data(sheet_name):
    try:
        gc = get_gsheet_client()
        sh = gc.open("yangyun_system_db")
        return sh.worksheet(sheet_name).get_all_records()
    except: return []

def save_data(data, sheet_name):
    try:
        gc = get_gsheet_client()
        sh = gc.open("yangyun_system_db")
        worksheet = sh.worksheet(sheet_name)
        worksheet.clear()
        if not data: return
        df = pd.DataFrame(data).fillna("")
        for col in df.columns:
            df[col] = df[col].apply(lambda x: json.dumps(x, ensure_ascii=False) if isinstance(x, (list, dict)) else x)
        worksheet.update([df.columns.values.tolist()] + df.values.tolist())
        return True
    except Exception as e:
        raise Exception(f"GSå†™å…¥å¤±è´¥: {e}")

# --- 3. GitHub å½’æ¡£ (å¢å¼ºç‰ˆ) ---
def push_to_github(filename, content, folder):
    token = get_config("GITHUB_TOKEN")
    if not token: 
        print(f"âš ï¸ ç¼ºå°‘ GITHUB_TOKENï¼Œæ— æ³•æ¨é€ {filename}")
        return None 
        
    try:
        g = Github(token)
        repo = g.get_user().get_repo("obsidian_notes") # ä½ çš„ä»“åº“å
        path = f"{folder}/{filename}"
        
        # PyGithub ä¼šè‡ªåŠ¨å¤„ç†çˆ¶æ–‡ä»¶å¤¹ä¸å­˜åœ¨çš„æƒ…å†µ
        try:
            contents = repo.get_contents(path)
            repo.update_file(path, f"Update {filename}", content, contents.sha)
            print(f"âœ… æ›´æ–°æ–‡ä»¶æˆåŠŸ: {path}")
        except:
            repo.create_file(path, f"Create {filename}", content)
            print(f"âœ… åˆ›å»ºæ–‡ä»¶æˆåŠŸ: {path}")
            
        return f"https://github.com/yangyungit/obsidian_notes/blob/main/{path}"
    except Exception as e:
        print(f"âŒ GitHub å½’æ¡£å¤±è´¥ [{path}]: {e}")
        return None

# --- 4. AI åˆ†æä¸åˆ†å‘ (æ ¸å¿ƒä¿®æ”¹ï¼š20å­—ç»“è®º) ---
def auto_dispatch(client, raw_text):
    api_key = get_config("GOOGLE_API_KEY")
    if not api_key: return []

    genai.configure(api_key=api_key)
    
    # ğŸ‘‡ Prompt ä¿®æ”¹ï¼šTitle å¿…é¡»æ˜¯ç»“è®ºï¼ŒLogic Chain å¿…é¡»æ¸…æ™°
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªé¡¶çº§å®è§‚å¯¹å†²åŸºé‡‘çš„æƒ…æŠ¥å®˜ã€‚è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬ã€‚
    
    ã€æ–‡æœ¬ã€‘ï¼š{raw_text[:6000]}
    
    ã€ä»»åŠ¡ã€‘ï¼š
    1. è¯†åˆ«ä¸»æ—¨ï¼Œæ‹†åˆ†ç‹¬ç«‹çš„å®è§‚/é›·è¾¾æƒ…æŠ¥ã€‚
    2. æå–åŸæ–‡æ—¶é—´ã€‚
    3. **å››ç»´æ‹†è§£**ï¼šäº‹å®ã€è§‚ç‚¹ã€é€»è¾‘ã€å‡è®¾ã€‚
    
    ã€è¾“å‡º JSON åˆ—è¡¨ã€‘ï¼š
    [
      {{
        "category": "MACRO" æˆ– "RADAR",
        "title": "æç®€ç»“è®º (å¿…é¡»åœ¨20å­—ä»¥å†…ï¼Œä¾‹å¦‚: ç¾è”å‚¨é¹°æ´¾è¨€è®ºå°†å‹åˆ¶ç§‘æŠ€è‚¡ä¼°å€¼)",
        "summary": "å®Œæ•´çš„æ‘˜è¦å†…å®¹ (ä¿ç•™ä¾›ä¾¦æŸ¥å®¤ä½¿ç”¨ï¼Œä½†ä¸åœ¨åˆ—è¡¨å±•ç¤º)",
        "bias": "Bullish/Bearish/Neutral",
        "tags": ["æ ‡ç­¾"],
        "logic_chain_display": "é€»è¾‘é“¾ (A -> B -> Cï¼Œç®€ç»ƒæœ‰åŠ›)",
        "publication_date": "åŸæ–‡æ—¶é—´", 
        "url": "åŸæ–‡é“¾æ¥",
        "deep_analysis_md": "è¯·æŒ‰ Markdown æ ¼å¼è¾“å‡ºï¼š\\n\\n### 1. äº‹å® (Facts)\\n...\\n\\n### 2. è§‚ç‚¹ (Opinions)\\n...\\n\\n### 3. é€»è¾‘ (Logic)\\n...\\n\\n### 4. å‡è®¾ (Assumptions)\\n..."
      }}
    ]
    """
    
    analysis_results = []
    for model_name in ['gemini-2.5-flash', 'gemini-2.0-flash']:
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            text = response.text.strip()
            if text.startswith("```json"): text = text[7:]
            if text.endswith("```"): text = text[:-3]
            analysis_results = json.loads(text)
            if not isinstance(analysis_results, list): analysis_results = [analysis_results]
            break
        except: continue
    
    if not analysis_results: return []

    final_items = []
    
    # 1. å½’æ¡£åŸæ–‡ (00_Inbox_AI)
    # å†æ¬¡å¼ºè°ƒï¼šè‡ªåŠ¨åˆ›å»ºæ–‡ä»¶å¤¹
    # å¢åŠ  .replace(' ', '_')
    safe_title = analysis_results[0].get('title', 'Untitled').replace('/', '_').replace(' ', '_')[:20]
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    raw_filename = f"{safe_title}_{timestamp}.md"
    
    raw_content = f"""# åŸæ–‡å½’æ¡£
    - **æŠ“å–æ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M")}
    - **åŸæ–‡æ—¶é—´**: {analysis_results[0].get('publication_date')}
    - **æ¥æº**: {analysis_results[0].get('url')}
    ---
    {raw_text}
    """
    
    # æ¨é€åˆ° 00 (PyGithub ä¼šè‡ªåŠ¨åˆ›å»º 00_Inbox_AI æ–‡ä»¶å¤¹)
    raw_link = push_to_github(raw_filename, raw_content, "00_Inbox_AI")
    
    # 2. å½’æ¡£çŸ¥è¯†å— (01/02)
    for item in analysis_results:
        item['date'] = datetime.now().strftime("%Y-%m-%d")
        
        # é“¾æ¥å®¹é”™
        item['raw_doc_link'] = raw_link if raw_link else "#error_no_token"
        
        # å¡ç‰‡å†…å®¹
        card_content = f"""# {item['title']}
        - **åˆ†ç±»**: {item['category']}
        - **åå‘**: {item['bias']}
        - **åŸæ–‡**: [ç‚¹å‡»è·³è½¬]({item['raw_doc_link']})
        
        ## æ·±åº¦ç»“æ„åŒ–åˆ†æ
        {item['deep_analysis_md']}
        """
        
        folder = "01_Macro_Research" if item.get('category') == "MACRO" else "02_Radar_Ticker"
        card_filename = f"{item['title'].replace('/', '_')}.md"
        
        card_link = push_to_github(card_filename, card_content, folder)
        item['card_link'] = card_link if card_link else "#error_no_token"
        
        final_items.append(item)
        
    return final_items